{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F5RaUZ0iXBaB"
   },
   "source": [
    "## Complaint Categorization Baseline Model\n",
    "\n",
    "Fast and efficient handling of complaints on consumer forums is vital to commerce industry today. This notebook presents a baseline approach towards solving this problem. Consumer complaints on financial products is taken as the dataset to establish results.\n",
    "\n",
    "Tf-idf (term frequency times inverse document frequency) scheme to weight individual tokens is often used in information retrieval. One of the advantage of tf-idf is reduce the impact of tokens that occur very frequently, hence offering little to none in terms of information.\n",
    "The tf-idf of term 't' in document 'd' is tf-idf(d, t) = tf(t) * idf(d, t), where tf(t) is the number of times t occurs while idf is given by idf(d, t) = log [(1 + n) / (1 + df(d,t) + 1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2030,
     "status": "ok",
     "timestamp": 1629442337304,
     "user": {
      "displayName": "Swastik Nayak",
      "photoUrl": "",
      "userId": "17005119539221418060"
     },
     "user_tz": -330
    },
    "id": "KKU3Av-XXBaD",
    "outputId": "17622ec7-ddf9-4124-f984-df714f86a62e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import required libraries\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#from gensim.models import Word2Vec\n",
    "#from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# nltk downloaded (run only once)\n",
    "nltk.download('stopwords',quiet=True) # stopword library\n",
    "nltk.download('wordnet', quiet=True) # wordnet library\n",
    "nltk.download('words', quiet=True) # words library\n",
    "nltk.download('punkt', quiet=True) # tokenize library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ch9ccOJ0godr",
    "outputId": "f71414ee-4de9-4bb1-e1dd-db7671b1c452"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 179776 entries, 0 to 179775\n",
      "Data columns (total 2 columns):\n",
      " #   Column                        Non-Null Count   Dtype \n",
      "---  ------                        --------------   ----- \n",
      " 0   Consumer complaint narrative  179776 non-null  object\n",
      " 1   Product                       179776 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 2.7+ MB\n",
      "None\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Consumer complaint narrative</th>\n",
       "      <th>Product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have outdated information on my credit repor...</td>\n",
       "      <td>Credit reporting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I purchased a new car on XXXX XXXX. The car de...</td>\n",
       "      <td>Consumer Loan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An account on my credit report has a mistaken ...</td>\n",
       "      <td>Credit reporting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This company refuses to provide me verificatio...</td>\n",
       "      <td>Debt collection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This complaint is in regards to Square Two Fin...</td>\n",
       "      <td>Debt collection</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Consumer complaint narrative           Product\n",
       "0  I have outdated information on my credit repor...  Credit reporting\n",
       "1  I purchased a new car on XXXX XXXX. The car de...     Consumer Loan\n",
       "2  An account on my credit report has a mistaken ...  Credit reporting\n",
       "3  This company refuses to provide me verificatio...   Debt collection\n",
       "4  This complaint is in regards to Square Two Fin...   Debt collection"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the dataset\n",
    "df = pd.read_csv('complaints.csv')\n",
    "\n",
    "# Information about the dataset\n",
    "print(df.info())\n",
    "print('-'*60)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y-OgiDs5godr"
   },
   "source": [
    "- There are no null values in the dataframe.\n",
    "- Further analysis will be based on 'Consumer complaint narrative' feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "COwaeZO2XBaG"
   },
   "source": [
    "### Typical Complaint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jw_3jqF5XBaH",
    "outputId": "c3001684-0236-447d-ff64-18f382d01112"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I have outdated information on my credit report that I have previously disputed that has yet to be removed this information is more then seven years old and does not meet credit reporting requirements'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Consumer complaint narrative'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4QXHqmFxXBaJ"
   },
   "source": [
    "### Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5xIzAd7SXBaK",
    "outputId": "a7bc8e90-6365-4c82-c245-6f7d8d422630"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Credit reporting' 'Consumer Loan' 'Debt collection' 'Mortgage'\n",
      " 'Credit card' 'Other financial service' 'Bank account or service'\n",
      " 'Student loan' 'Money transfers' 'Payday loan' 'Prepaid card'\n",
      " 'Virtual currency'\n",
      " 'Credit reporting, credit repair services, or other personal consumer reports'\n",
      " 'Credit card or prepaid card' 'Checking or savings account'\n",
      " 'Payday loan, title loan, or personal loan'\n",
      " 'Money transfer, virtual currency, or money service'\n",
      " 'Vehicle loan or lease']\n"
     ]
    }
   ],
   "source": [
    "print(df.Product.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lwPZeTengodt"
   },
   "source": [
    "# Different Preprocessing steps\n",
    "- Method 1 = Normalization + Tokenization\n",
    "    - Normalization = Lower case + Remove Punctuation\n",
    "- Method 2 = Method1 + Lemmatization + Stop_words\n",
    "- Method 3 = Method2 + Remove alphanumeric tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KJZr5xzBgodu"
   },
   "source": [
    "### Method 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uDv6umIHgodu"
   },
   "outputs": [],
   "source": [
    "# Normalization\n",
    "\n",
    "def lower_case(text):\n",
    "  return text.lower()\n",
    "def remove_punctuation(text):\n",
    "  return re.sub('[^a-zA-Z]',' ', str(text))\n",
    "\n",
    "def normalize_document(text):\n",
    "    text = remove_punctuation(text)\n",
    "    text = lower_case(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gYw-W-izgodv",
    "outputId": "a4bbcfed-e48d-4b38-cb29-5274ef6eaa20"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Consumer complaint narrative</th>\n",
       "      <th>Product</th>\n",
       "      <th>normalize_document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have outdated information on my credit repor...</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>i have outdated information on my credit repor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I purchased a new car on XXXX XXXX. The car de...</td>\n",
       "      <td>Consumer Loan</td>\n",
       "      <td>i purchased a new car on xxxx xxxx  the car de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An account on my credit report has a mistaken ...</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>an account on my credit report has a mistaken ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This company refuses to provide me verificatio...</td>\n",
       "      <td>Debt collection</td>\n",
       "      <td>this company refuses to provide me verificatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This complaint is in regards to Square Two Fin...</td>\n",
       "      <td>Debt collection</td>\n",
       "      <td>this complaint is in regards to square two fin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Consumer complaint narrative           Product  \\\n",
       "0  I have outdated information on my credit repor...  Credit reporting   \n",
       "1  I purchased a new car on XXXX XXXX. The car de...     Consumer Loan   \n",
       "2  An account on my credit report has a mistaken ...  Credit reporting   \n",
       "3  This company refuses to provide me verificatio...   Debt collection   \n",
       "4  This complaint is in regards to Square Two Fin...   Debt collection   \n",
       "\n",
       "                                  normalize_document  \n",
       "0  i have outdated information on my credit repor...  \n",
       "1  i purchased a new car on xxxx xxxx  the car de...  \n",
       "2  an account on my credit report has a mistaken ...  \n",
       "3  this company refuses to provide me verificatio...  \n",
       "4  this complaint is in regards to square two fin...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['normalize_document'] = df['Consumer complaint narrative'].apply(normalize_document)\n",
    "df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QDNm4QdFgodv",
    "outputId": "ff09aaeb-3dbd-4e0d-af57-3cac1164e28c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Consumer complaint narrative</th>\n",
       "      <th>Product</th>\n",
       "      <th>normalize_document</th>\n",
       "      <th>Method1_doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have outdated information on my credit repor...</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>i have outdated information on my credit repor...</td>\n",
       "      <td>[i, have, outdated, information, on, my, credi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I purchased a new car on XXXX XXXX. The car de...</td>\n",
       "      <td>Consumer Loan</td>\n",
       "      <td>i purchased a new car on xxxx xxxx  the car de...</td>\n",
       "      <td>[i, purchased, a, new, car, on, xxxx, xxxx, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An account on my credit report has a mistaken ...</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>an account on my credit report has a mistaken ...</td>\n",
       "      <td>[an, account, on, my, credit, report, has, a, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This company refuses to provide me verificatio...</td>\n",
       "      <td>Debt collection</td>\n",
       "      <td>this company refuses to provide me verificatio...</td>\n",
       "      <td>[this, company, refuses, to, provide, me, veri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This complaint is in regards to Square Two Fin...</td>\n",
       "      <td>Debt collection</td>\n",
       "      <td>this complaint is in regards to square two fin...</td>\n",
       "      <td>[this, complaint, is, in, regards, to, square,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Consumer complaint narrative           Product  \\\n",
       "0  I have outdated information on my credit repor...  Credit reporting   \n",
       "1  I purchased a new car on XXXX XXXX. The car de...     Consumer Loan   \n",
       "2  An account on my credit report has a mistaken ...  Credit reporting   \n",
       "3  This company refuses to provide me verificatio...   Debt collection   \n",
       "4  This complaint is in regards to Square Two Fin...   Debt collection   \n",
       "\n",
       "                                  normalize_document  \\\n",
       "0  i have outdated information on my credit repor...   \n",
       "1  i purchased a new car on xxxx xxxx  the car de...   \n",
       "2  an account on my credit report has a mistaken ...   \n",
       "3  this company refuses to provide me verificatio...   \n",
       "4  this complaint is in regards to square two fin...   \n",
       "\n",
       "                                         Method1_doc  \n",
       "0  [i, have, outdated, information, on, my, credi...  \n",
       "1  [i, purchased, a, new, car, on, xxxx, xxxx, th...  \n",
       "2  [an, account, on, my, credit, report, has, a, ...  \n",
       "3  [this, company, refuses, to, provide, me, veri...  \n",
       "4  [this, complaint, is, in, regards, to, square,...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize the normalized_documents\n",
    "df['Method1_doc'] = df['normalize_document'].apply(lambda x : nltk.word_tokenize(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bcYC1uE6godv",
    "outputId": "3e7072f5-ad5b-4d79-f6c0-ce051b81b7f5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Consumer complaint narrative</th>\n",
       "      <th>Product</th>\n",
       "      <th>Method1_doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have outdated information on my credit repor...</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>[i, have, outdated, information, on, my, credi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I purchased a new car on XXXX XXXX. The car de...</td>\n",
       "      <td>Consumer Loan</td>\n",
       "      <td>[i, purchased, a, new, car, on, xxxx, xxxx, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An account on my credit report has a mistaken ...</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>[an, account, on, my, credit, report, has, a, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This company refuses to provide me verificatio...</td>\n",
       "      <td>Debt collection</td>\n",
       "      <td>[this, company, refuses, to, provide, me, veri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This complaint is in regards to Square Two Fin...</td>\n",
       "      <td>Debt collection</td>\n",
       "      <td>[this, complaint, is, in, regards, to, square,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Consumer complaint narrative           Product  \\\n",
       "0  I have outdated information on my credit repor...  Credit reporting   \n",
       "1  I purchased a new car on XXXX XXXX. The car de...     Consumer Loan   \n",
       "2  An account on my credit report has a mistaken ...  Credit reporting   \n",
       "3  This company refuses to provide me verificatio...   Debt collection   \n",
       "4  This complaint is in regards to Square Two Fin...   Debt collection   \n",
       "\n",
       "                                         Method1_doc  \n",
       "0  [i, have, outdated, information, on, my, credi...  \n",
       "1  [i, purchased, a, new, car, on, xxxx, xxxx, th...  \n",
       "2  [an, account, on, my, credit, report, has, a, ...  \n",
       "3  [this, company, refuses, to, provide, me, veri...  \n",
       "4  [this, complaint, is, in, regards, to, square,...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove normalize_document feature\n",
    "df.drop(columns=['normalize_document'], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-CoO4Xygodw"
   },
   "source": [
    "### Method 2 = Method 1 + Lemmatization + Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QaYe4LFugodw"
   },
   "outputs": [],
   "source": [
    "stops = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "#ps = PorterStemmer()\n",
    "def method2(text, lemma=True):\n",
    "    \n",
    "    sample = text\n",
    "    \n",
    "    # Removing stopwords\n",
    "    sample = [word for word in sample if not word in stops]\n",
    "    sample = ' '.join(sample) # This step is not needed if lemmatization is done \n",
    "    \n",
    "    # Lemmatization\n",
    "    if lemma:\n",
    "        sample = sample.split()\n",
    "        sample = [lemmatizer.lemmatize(word) for word in sample]\n",
    "        sample = ' '.join(sample)\n",
    "    \n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oX8EkTHegodw",
    "outputId": "cbbe8fef-c7de-44c2-f20e-a4b5bd890779"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Consumer complaint narrative</th>\n",
       "      <th>Product</th>\n",
       "      <th>Method1_doc</th>\n",
       "      <th>Method2_doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have outdated information on my credit repor...</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>[i, have, outdated, information, on, my, credi...</td>\n",
       "      <td>outdated information credit report previously ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I purchased a new car on XXXX XXXX. The car de...</td>\n",
       "      <td>Consumer Loan</td>\n",
       "      <td>[i, purchased, a, new, car, on, xxxx, xxxx, th...</td>\n",
       "      <td>purchased new car xxxx xxxx car dealer called ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An account on my credit report has a mistaken ...</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>[an, account, on, my, credit, report, has, a, ...</td>\n",
       "      <td>account credit report mistaken date mailed deb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This company refuses to provide me verificatio...</td>\n",
       "      <td>Debt collection</td>\n",
       "      <td>[this, company, refuses, to, provide, me, veri...</td>\n",
       "      <td>company refuse provide verification validation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This complaint is in regards to Square Two Fin...</td>\n",
       "      <td>Debt collection</td>\n",
       "      <td>[this, complaint, is, in, regards, to, square,...</td>\n",
       "      <td>complaint regard square two financial refer cf...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Consumer complaint narrative           Product  \\\n",
       "0  I have outdated information on my credit repor...  Credit reporting   \n",
       "1  I purchased a new car on XXXX XXXX. The car de...     Consumer Loan   \n",
       "2  An account on my credit report has a mistaken ...  Credit reporting   \n",
       "3  This company refuses to provide me verificatio...   Debt collection   \n",
       "4  This complaint is in regards to Square Two Fin...   Debt collection   \n",
       "\n",
       "                                         Method1_doc  \\\n",
       "0  [i, have, outdated, information, on, my, credi...   \n",
       "1  [i, purchased, a, new, car, on, xxxx, xxxx, th...   \n",
       "2  [an, account, on, my, credit, report, has, a, ...   \n",
       "3  [this, company, refuses, to, provide, me, veri...   \n",
       "4  [this, complaint, is, in, regards, to, square,...   \n",
       "\n",
       "                                         Method2_doc  \n",
       "0  outdated information credit report previously ...  \n",
       "1  purchased new car xxxx xxxx car dealer called ...  \n",
       "2  account credit report mistaken date mailed deb...  \n",
       "3  company refuse provide verification validation...  \n",
       "4  complaint regard square two financial refer cf...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Method2_doc'] = df['Method1_doc'].apply(method2)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OvllBPE_godx"
   },
   "source": [
    "### Method 3 = Method 2 + Remove alpha numeric tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "79YP1kpfgodx"
   },
   "outputs": [],
   "source": [
    "only_english = set(nltk.corpus.words.words())\n",
    "def method3(text):\n",
    "    \n",
    "    sample = text\n",
    "    sample = re.sub(r\"\\S*https?:\\S*\", '', sample) #links and urls\n",
    "    sample = re.sub('\\[.*?\\]', '', sample) #text between [square brackets]\n",
    "    sample = re.sub('\\(.*?\\)', '', sample) #text between (parenthesis)\n",
    "    sample = re.sub('[%s]' % re.escape(string.punctuation), '', sample) #punctuations\n",
    "    sample = re.sub('\\w*\\d\\w', '', sample) #digits with trailing or preceeding text\n",
    "    sample = re.sub(r'\\n', ' ', sample) #new line character\n",
    "    sample = re.sub(r'\\\\n', ' ', sample) #new line character\n",
    "    sample = re.sub(\"[''\"\"...“”‘’…]\", '', sample) #list of quotation marks\n",
    "    sample = re.sub(r', /<[^>]+>/', '', sample)    #HTML attributes\n",
    "    \n",
    "    sample = ' '.join([w for w in nltk.wordpunct_tokenize(sample) if w.lower() in only_english or not w.isalpha()]) #doesn't remove indian languages\n",
    "    sample = ' '.join(list(filter(lambda ele: re.search(\"[a-zA-Z\\s]+\", ele) is not None, sample.split()))) #languages other than english\n",
    "    \n",
    "    sample = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               u\"\\U0001f926-\\U0001f937\"\n",
    "                               u\"\\U00010000-\\U0010ffff\"\n",
    "                               u\"\\u2640-\\u2642\"\n",
    "                               u\"\\u2600-\\u2B55\"\n",
    "                               u\"\\u200d\"\n",
    "                               u\"\\u23cf\"\n",
    "                               u\"\\u23e9\"\n",
    "                               u\"\\u231a\"\n",
    "                               u\"\\ufe0f\"  # dingbats\n",
    "                               u\"\\u3030\"\n",
    "                               \"]+\", flags=re.UNICODE).sub(r'', sample) #emojis and symbols\n",
    "    sample = sample.strip()\n",
    "    sample = \" \".join([x.strip() for x in sample.split()])\n",
    "    \n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qgity5b8godx",
    "outputId": "7e073e49-b322-461d-a7ff-d2482c0d8d7f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Consumer complaint narrative</th>\n",
       "      <th>Method1_doc</th>\n",
       "      <th>Method2_doc</th>\n",
       "      <th>Method3_doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have outdated information on my credit repor...</td>\n",
       "      <td>[i, have, outdated, information, on, my, credi...</td>\n",
       "      <td>outdated information credit report previously ...</td>\n",
       "      <td>outdated information credit report previously ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I purchased a new car on XXXX XXXX. The car de...</td>\n",
       "      <td>[i, purchased, a, new, car, on, xxxx, xxxx, th...</td>\n",
       "      <td>purchased new car xxxx xxxx car dealer called ...</td>\n",
       "      <td>new car car dealer citizen bank get day payoff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An account on my credit report has a mistaken ...</td>\n",
       "      <td>[an, account, on, my, credit, report, has, a, ...</td>\n",
       "      <td>account credit report mistaken date mailed deb...</td>\n",
       "      <td>account credit report mistaken date mailed deb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This company refuses to provide me verificatio...</td>\n",
       "      <td>[this, company, refuses, to, provide, me, veri...</td>\n",
       "      <td>company refuse provide verification validation...</td>\n",
       "      <td>company refuse provide verification validation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This complaint is in regards to Square Two Fin...</td>\n",
       "      <td>[this, complaint, is, in, regards, to, square,...</td>\n",
       "      <td>complaint regard square two financial refer cf...</td>\n",
       "      <td>complaint regard square two financial refer ca...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Consumer complaint narrative  \\\n",
       "0  I have outdated information on my credit repor...   \n",
       "1  I purchased a new car on XXXX XXXX. The car de...   \n",
       "2  An account on my credit report has a mistaken ...   \n",
       "3  This company refuses to provide me verificatio...   \n",
       "4  This complaint is in regards to Square Two Fin...   \n",
       "\n",
       "                                         Method1_doc  \\\n",
       "0  [i, have, outdated, information, on, my, credi...   \n",
       "1  [i, purchased, a, new, car, on, xxxx, xxxx, th...   \n",
       "2  [an, account, on, my, credit, report, has, a, ...   \n",
       "3  [this, company, refuses, to, provide, me, veri...   \n",
       "4  [this, complaint, is, in, regards, to, square,...   \n",
       "\n",
       "                                         Method2_doc  \\\n",
       "0  outdated information credit report previously ...   \n",
       "1  purchased new car xxxx xxxx car dealer called ...   \n",
       "2  account credit report mistaken date mailed deb...   \n",
       "3  company refuse provide verification validation...   \n",
       "4  complaint regard square two financial refer cf...   \n",
       "\n",
       "                                         Method3_doc  \n",
       "0  outdated information credit report previously ...  \n",
       "1  new car car dealer citizen bank get day payoff...  \n",
       "2  account credit report mistaken date mailed deb...  \n",
       "3  company refuse provide verification validation...  \n",
       "4  complaint regard square two financial refer ca...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Method3_doc'] = df['Method2_doc'].apply(method3)\n",
    "df.loc[:, ['Consumer complaint narrative', 'Method1_doc', 'Method2_doc', 'Method3_doc']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mr_CVhn6gody"
   },
   "source": [
    "### Bag_of_words\n",
    "- Bag of words (BOW) is a technique to extract features from the text \n",
    "- The words that are obtained after all the preprocessing steps\n",
    "- The bag of word model focuses on the word count to represent a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SItDQYdfgody",
    "outputId": "e7f8cf10-58af-4436-e655-f0388af4b1bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key : ['account', 'credit', 'payment', 'loan', 'would', 'time', 'bank', 'report', 'debt', 'told', 'n', 'information', 'call', 'company', 'received', 'card', 'mortgage', 'day', 'month', 'letter']\n",
      "Total_Keys: 19017\n",
      "----------------------------------------\n",
      "[[0. 0. 2. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 2. 3. ... 0. 0. 0.]\n",
      " [0. 0. 3. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "text =df['Method3_doc']\n",
    "sentence = []\n",
    "for i in text:\n",
    "    sentence.append(i)\n",
    "\n",
    "# using tokenizer \n",
    "model = Tokenizer()\n",
    "model.fit_on_texts(sentence)\n",
    "\n",
    "#print keys \n",
    "keys = list(model.word_index.keys())\n",
    "print(f'Key : {keys[0:20]}')\n",
    "print('Total_Keys:', len(keys)) \n",
    "print('-'*40)\n",
    "\n",
    "#create bag of words representation \n",
    "bow = model.texts_to_matrix(sentence, mode='count')\n",
    "print(bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "heUPEzf8gody"
   },
   "source": [
    "### TF-IDF Experiment\n",
    "- TF-IDF vectorizer will be applied on all the three preprocessing methods\n",
    "- Based on that the importance of different terms for each method can be compared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XP7PgdF_gody"
   },
   "source": [
    "### Method 1 \n",
    "- As the first method has the preprocessed document in the form of tokens the TF-IDF is defined as shown in the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DbN-YygDgodz"
   },
   "outputs": [],
   "source": [
    "# Defining TF-IDF vectorizer\n",
    "\n",
    "def dummy_fun(doc):\n",
    "    return doc\n",
    "\n",
    "tfidf = TfidfVectorizer(analyzer='word',\n",
    "                        tokenizer=dummy_fun,\n",
    "                        preprocessor=dummy_fun,\n",
    "                        token_pattern=None,\n",
    "                        stop_words = 'english') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RJlpPsaEgodz",
    "outputId": "2acc35f5-cc95-474e-a664-c6770fced7b8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gowthamswaminathan/opt/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:391: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(179776, 78812)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_method1 = tfidf.fit_transform(df.Method1_doc)\n",
    "tfidf_method1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3gPT_TAigodz"
   },
   "outputs": [],
   "source": [
    "# Create Data Frame of tdidf scores\n",
    "tfidf_df_method1 = pd.DataFrame(tfidf_method1.toarray(),\n",
    "             columns = tfidf.get_feature_names(),\n",
    "             index = df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EHZkXA6Wgodz",
    "outputId": "13b54963-b6ef-4802-93f8-30caf17998ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xxxx           0.169184\n",
       "credit         0.048357\n",
       "xx             0.047034\n",
       "account        0.041912\n",
       "debt           0.030252\n",
       "report         0.029436\n",
       "loan           0.028440\n",
       "payment        0.026103\n",
       "bank           0.024022\n",
       "information    0.021939\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate tfidf for all columns and list top 10\n",
    "tfidf_df_method1.mean().sort_values(ascending = False).head(10)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T0-t3d3hgodz"
   },
   "source": [
    "### TD-IDF Method2\n",
    "- Here the convetional way of defining TF-IDF is done as the method2 preprocessing returns sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5r60wwISgodz",
    "outputId": "5046ce21-78ad-440d-da10-7d0982afe5af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(179776, 74110)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer_tfidf = TfidfVectorizer(stop_words = set(nltk.corpus.stopwords.words('english')))\n",
    "tfidf_method2 = vectorizer_tfidf.fit_transform(df.Method2_doc)\n",
    "tfidf_method2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4HRmRcgUgod0"
   },
   "outputs": [],
   "source": [
    "# Create Data Frame of tdidf scores\n",
    "tfidf_df_method2 = pd.DataFrame(tfidf_method2.toarray(),\n",
    "             columns = vectorizer_tfidf.get_feature_names(),\n",
    "             index = df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "odtyL3d-god0",
    "outputId": "6c83baca-b835-4430-86dd-d301082e7363"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xxxx       0.168266\n",
       "credit     0.048320\n",
       "account    0.046734\n",
       "xx         0.046716\n",
       "payment    0.036594\n",
       "loan       0.033560\n",
       "report     0.032294\n",
       "debt       0.031119\n",
       "bank       0.024618\n",
       "company    0.023310\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate tfidf for all columns and list top 10\n",
    "tfidf_df_method2.mean().sort_values(ascending = False).head(10)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7A2EZIAHgod0"
   },
   "source": [
    "### TF - IDF Method 3\n",
    "- Here the convetional way of defining TF-IDF is done as the method3 preprocessing returns sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m2Yq4LYKgod0",
    "outputId": "a7b99024-660c-4733-9f8b-47dee3d08b87"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(179776, 18961)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer_tfidf = TfidfVectorizer(stop_words = set(nltk.corpus.stopwords.words('english')))\n",
    "tfidf_method3 = vectorizer_tfidf.fit_transform(df.Method3_doc)\n",
    "tfidf_method3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7U3p_NbAgod0"
   },
   "outputs": [],
   "source": [
    "# Create Data Frame of tdidf scores\n",
    "tfidf_df_method3 = pd.DataFrame(tfidf_method3.toarray(),\n",
    "             columns = vectorizer_tfidf.get_feature_names(),\n",
    "             index = df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WtuPkZJNgod0",
    "outputId": "73be75de-9f65-49bc-b544-ff92867e7693"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "credit     0.058716\n",
       "account    0.057299\n",
       "payment    0.044387\n",
       "loan       0.040472\n",
       "report     0.039748\n",
       "debt       0.037294\n",
       "bank       0.029835\n",
       "company    0.027746\n",
       "card       0.027173\n",
       "would      0.026787\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate tfidf for all columns and list top 10\n",
    "tfidf_df_method3.mean().sort_values(ascending = False).head(10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JXYa2vhugod1"
   },
   "source": [
    "- TF-IDF vectorizer is analyzed for all the three pre-processing techniques and the results are shown with top10 frequently occuring words in the consumer complaint narrative text.\n",
    "- Further model training will be done with all the preprocessing techniques seperately and the results will be compared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cwS4qyhGXBaM"
   },
   "source": [
    "### Training a model with Method1 preprocessing\n",
    "- Train-test split - 15% of the total data is used as validation data while the remaining as training. This leads to 152809 training instances while 26967 validation instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WSvgRwB5god1"
   },
   "outputs": [],
   "source": [
    "def sentence(text):\n",
    "    sent = ' '.join(text)\n",
    "    #for i in txt:\n",
    "     #   sent.append(' '.join(i))\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9o1cu48ngod1",
    "outputId": "52a8c801-d3a2-4a96-8d7a-0c91071b3106"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Consumer complaint narrative</th>\n",
       "      <th>Product</th>\n",
       "      <th>Method1_doc</th>\n",
       "      <th>Method1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have outdated information on my credit repor...</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>[i, have, outdated, information, on, my, credi...</td>\n",
       "      <td>i have outdated information on my credit repor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I purchased a new car on XXXX XXXX. The car de...</td>\n",
       "      <td>Consumer Loan</td>\n",
       "      <td>[i, purchased, a, new, car, on, xxxx, xxxx, th...</td>\n",
       "      <td>i purchased a new car on xxxx xxxx the car dea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An account on my credit report has a mistaken ...</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>[an, account, on, my, credit, report, has, a, ...</td>\n",
       "      <td>an account on my credit report has a mistaken ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This company refuses to provide me verificatio...</td>\n",
       "      <td>Debt collection</td>\n",
       "      <td>[this, company, refuses, to, provide, me, veri...</td>\n",
       "      <td>this company refuses to provide me verificatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This complaint is in regards to Square Two Fin...</td>\n",
       "      <td>Debt collection</td>\n",
       "      <td>[this, complaint, is, in, regards, to, square,...</td>\n",
       "      <td>this complaint is in regards to square two fin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Consumer complaint narrative           Product  \\\n",
       "0  I have outdated information on my credit repor...  Credit reporting   \n",
       "1  I purchased a new car on XXXX XXXX. The car de...     Consumer Loan   \n",
       "2  An account on my credit report has a mistaken ...  Credit reporting   \n",
       "3  This company refuses to provide me verificatio...   Debt collection   \n",
       "4  This complaint is in regards to Square Two Fin...   Debt collection   \n",
       "\n",
       "                                         Method1_doc  \\\n",
       "0  [i, have, outdated, information, on, my, credi...   \n",
       "1  [i, purchased, a, new, car, on, xxxx, xxxx, th...   \n",
       "2  [an, account, on, my, credit, report, has, a, ...   \n",
       "3  [this, company, refuses, to, provide, me, veri...   \n",
       "4  [this, complaint, is, in, regards, to, square,...   \n",
       "\n",
       "                                             Method1  \n",
       "0  i have outdated information on my credit repor...  \n",
       "1  i purchased a new car on xxxx xxxx the car dea...  \n",
       "2  an account on my credit report has a mistaken ...  \n",
       "3  this company refuses to provide me verificatio...  \n",
       "4  this complaint is in regards to square two fin...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Method1'] = df['Method1_doc'].apply(sentence)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RcHsVb4GXBaN",
    "outputId": "f3ba9442-057d-467a-f518-e6ff0ddc70b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training utterances: 152809\n",
      "Validation utterances: 26967\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['Method1'].values, df['Product'].values, test_size=0.15, random_state=42)\n",
    "print('Training utterances: {}'.format(X_train.shape[0]))\n",
    "print('Validation utterances: {}'.format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AxKJJZn8XBaP"
   },
   "source": [
    "##### Calculating tf-idf scores\n",
    "Calculating tf-idf scores for each unique token in the dataset and creating frequency chart for each utterance in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ut2qdu8HXBaP",
    "outputId": "f1a62af5-5b7e-44e6-f26c-6b9cfae12525"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer()"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "luNy0LXQXBaR",
    "outputId": "2ddb2395-44ea-4ba5-f190-e3e154a8c3e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<152809x72535 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 13620353 stored elements in Compressed Sparse Row format>,\n",
       " <26967x72535 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 2397990 stored elements in Compressed Sparse Row format>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = vectorizer.transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "X_train, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XnG6cE6GXBaT"
   },
   "source": [
    "##### Feature Selection\n",
    "Chi-square test measures dependence between stochastic variables, so using this function “weeds out” the features that are the most likely to be independent of class and therefore irrelevant for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9eZdPs2fXBaU",
    "outputId": "2db6881f-b2bb-49c5-eb02-f8c2765a2295"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<152809x5000 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 10704472 stored elements in Compressed Sparse Row format>,\n",
       " <26967x5000 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 1889836 stored elements in Compressed Sparse Row format>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "ch2 = SelectKBest(chi2, k=5000)\n",
    "X_train = ch2.fit_transform(X_train, y_train)\n",
    "X_test = ch2.transform(X_test)\n",
    "\n",
    "X_train, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qez31NMtXBaW"
   },
   "source": [
    "##### Naive Bayes\n",
    "In multinomial naive bayes the probability of a document $d$ being in class $c$ is computed as $$P(c|d) = P(c) \\prod_{1\\le k \\le n_d}{P(t_k|c)} $$ where, $P(c)$ is the prior probablity of a document occuring in class $c$ and $P(t_k|c)$ is the conditional probability of term $t_k$ occurring in a document of class $c$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VI4oeUxsXBaW",
    "outputId": "1a323811-5f4a-4cc8-a5ee-b0d94eb3f86c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7624133199836838\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "model_mnb_m1 = MultinomialNB()\n",
    "model_mnb_m1.fit(X_train, y_train)\n",
    "pred = model_mnb_m1.predict(X_test)\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XoWC-6m1god2"
   },
   "source": [
    "### With minimum preprocessing the accuracy obtained is 76%. Let us try to train the model with the other preprocessing techniques too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rinTqLnygod2",
    "outputId": "bd7953c9-0837-42aa-be57-b1e5bddfb338"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training utterances: 152809\n",
      "Validation utterances: 26967\n",
      "0.7655653205770016\n"
     ]
    }
   ],
   "source": [
    "# Training the model with Method 2 preprocessing\n",
    "\n",
    "## Train_Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Method2_doc'].values, df['Product'].values, test_size=0.15, random_state=42)\n",
    "print('Training utterances: {}'.format(X_train.shape[0]))\n",
    "print('Validation utterances: {}'.format(X_test.shape[0]))\n",
    "\n",
    "## TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(X_train)\n",
    "X_train = vectorizer.transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "## Feature Selection\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "ch2 = SelectKBest(chi2, k=5000)\n",
    "X_train = ch2.fit_transform(X_train, y_train)\n",
    "X_test = ch2.transform(X_test)\n",
    "\n",
    "## Model Testing\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "model_mnb_m2 = MultinomialNB()\n",
    "model_mnb_m2.fit(X_train, y_train)\n",
    "pred = model_mnb_m2.predict(X_test)\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qDtkPZF3god3",
    "outputId": "5d684754-562b-4fe9-fa1a-7136443baa20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training utterances: 152809\n",
      "Validation utterances: 26967\n",
      "0.7340823970037453\n"
     ]
    }
   ],
   "source": [
    "# Training the model with Method 3 preprocessing\n",
    "\n",
    "## Train_Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Method3_doc'].values, df['Product'].values, test_size=0.15, random_state=42)\n",
    "print('Training utterances: {}'.format(X_train.shape[0]))\n",
    "print('Validation utterances: {}'.format(X_test.shape[0]))\n",
    "\n",
    "## TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(X_train)\n",
    "X_train = vectorizer.transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "## Feature Selection\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "ch2 = SelectKBest(chi2, k=5000)\n",
    "X_train = ch2.fit_transform(X_train, y_train)\n",
    "X_test = ch2.transform(X_test)\n",
    "\n",
    "## Model Testing\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "model_mnb_m3 = MultinomialNB()\n",
    "model_mnb_m3.fit(X_train, y_train)\n",
    "pred = model_mnb_m3.predict(X_test)\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7nZ1-VY_god3"
   },
   "source": [
    "- The comparitive analysis clearly potraits that too much preprocessing will result in reduction in model performance as some important words/characters are unncessarily removed."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "heUPEzf8gody"
   ],
   "name": "complaint_classification_case_study.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "1bcaa234541af14269647e78a58ff1e2c97283aefba8e8df69f3d751152a4c75"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
